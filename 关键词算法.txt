论文分类中，需要为每一篇论文找出关键词。

其中，有的论文有关键词，有的论文没有关键词。有的关键词中很多掺了很多英文，这些都被过滤掉了，导致关键词数量太少。我们需要一个生成关键词及权重的算法。

1. 选择关键词

将所有的语料(标题+摘要分词后，和训练词向量的语料一样)输入TF-IDF模型，计算每篇论文中每个词的 tf-idf值，保存模型，这个和词向量都是基础数据。

对于每篇论文，标题+摘要+关键词(如果有的话)，是一个词列表，通过TF-IDF模型计算词列表中每个词的tf-idf值。按照tf-idf值进行排序，挑选tf-idf值比较高的10~15个值作为关键词。


2. 关键词权重

对每篇论文挑选出关键词列表，计算权重时考虑两方面的因素：

(1) 关键词的tf-idf值，tf-idf值越高，权重也应该越高。

(2) 关键词与各个领域中心点距离的差异性。理想情况下，一个词属于某一个领域而不属于其他领域，就是这个词与目标领域的距离很近而与其他领域距离都很远；若一个词距离所有领域

     的距离都差不多，那么这个词就是“普通词”，没有很强的区分度，应该被赋予小的权重。考虑一下如何表示这种差异性。

     比如，一个词与各个领域中心点的距离为: [ area1_distance, area2_distance,...] , 距离的方差应该可以大致表示差异性，方差越大，表示这个词差异性越好。

 最后，考虑这两方面的因素，设计一个权重函数F, 其中degree_diff表示差异性：

 keyword_weight = F(tf-idf,degree_diff)  ，计算keyword的权重。


 选择合适的关键词，并赋予相应的权重对最后的分类效果影响很大。










